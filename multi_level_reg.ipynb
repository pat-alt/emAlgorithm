{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n",
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: microbenchmark\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Loading required package: fromScratchR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Packages -----\n",
    "cran_packages <- list(\n",
    "    \"Rcpp\",\n",
    "    \"data.table\",\n",
    "    \"microbenchmark\",\n",
    "    \"ggplot2\"\n",
    ")\n",
    "invisible(\n",
    "    lapply(\n",
    "        cran_packages,\n",
    "        function(i) {\n",
    "            if (!require(i, character.only = T)) {\n",
    "                install.packages(i)\n",
    "                library(i, character.only = T)\n",
    "            } else {\n",
    "                library(i, character.only = T)\n",
    "            }\n",
    "        }\n",
    "    )\n",
    ")\n",
    "# Package containing a set of helper functions:\n",
    "if (!require(fromScratchR)) {\n",
    "    devtools::install_github(\"pat-alt/fromScratchR\")\n",
    "    library(fromScratchR)\n",
    "} else {\n",
    "    library(fromScratchR)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-level regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a multilevel regression model with group level predictors (varying intercepts) as in Gelman, Hill (2007). For the first level we have for individual $i\\in[1,N]$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&& y_i &= z_{j[i]} + \\mathbf{X}_i^T \\beta + \\varepsilon_i, && \\varepsilon_i \\sim \\mathcal{N}(0, \\phi)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{X}_i$ is a $(K \\times 1)$ vector of individual-level predictors. Consequently we have that \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&& y_i|z_j[i], \\mathbf{X}_i &\\sim \\mathcal{N}(z_{j[i]} + \\mathbf{X}_i^T \\beta, \\phi)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\phi^{-1}$ can be thought of as the precision of the data. \n",
    "\n",
    "For the second level we have for group $j\\in[1,M]$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&& z_j &= \\mathbf{u}_j^T \\gamma + \\eta_j, && \\eta_j \\sim \\mathcal{N}(0, \\psi)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $z_j$ are unobserved and $\\mathbf{u}_j$ is $(L \\times 1)$ vector of observed group-level predictors.\n",
    "\n",
    "Consequently we have that \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&& z_j|\\mathbf{u}_j&\\sim \\mathcal{N}(\\mathbf{u}_j^T \\gamma, \\psi)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\psi^{-1}$ can be thought of as the precision of the latent factors. To simulate data from this model we can use the helper function below. For now we will look at a single set of default parameter choices. Note that the choices for `phi` and `psi` roughly imply that the latent, group-level information is twice as precise as the individual level data. We would therefore expect the algorithm to produce final posterior densities of the latent variables that are are more similar to their estimated prior density then the likelihood of the observed data given the latent variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_multi_level_reg <- function(\n",
    "  N=10000,\n",
    "  M=1000,\n",
    "  beta=c(1,0.1),\n",
    "  phi=0.1,\n",
    "  a=1,\n",
    "  b=0.5,\n",
    "  psi=0.05,\n",
    "  seed=123\n",
    ") {\n",
    "  set.seed(seed)\n",
    "  # 1.) Latent factors: ----\n",
    "  u <- matrix(rnorm(M))\n",
    "  z <- a + b * u + rnorm(n=nrow(u),sd=sqrt(psi))\n",
    "  # Group lengths:\n",
    "  wgts <- runif(M)\n",
    "  wgts <- wgts/sum(wgts)\n",
    "  n_j <- pmax(round(wgts * N),10)\n",
    "  to_allocate <- N - sum(n_j)\n",
    "  while (to_allocate!=0) {\n",
    "    if (to_allocate > 0) {\n",
    "      idx <- sample(M,1)\n",
    "      n_j[idx] <- n_j[idx] + 1\n",
    "      to_allocate <- to_allocate - 1\n",
    "    } else {\n",
    "      idx <- sample(M,1)\n",
    "      n_j[idx] <- n_j[idx] - 1\n",
    "      to_allocate <- to_allocate + 1\n",
    "    }\n",
    "  }\n",
    "  Z <- rep(0, N)\n",
    "  from <- 1\n",
    "  for (j in 1:M) {\n",
    "    idx <- from:(from+n_j[j]-1)\n",
    "    Z[idx] <- z[j]\n",
    "    from <- from + n_j[j]\n",
    "  }\n",
    "  # 2.) Output: ----\n",
    "  K <- length(beta)\n",
    "  X <- matrix(rnorm(N*K), nrow=N)\n",
    "  y <- Z + X %*% beta + rnorm(n=nrow(X),sd=sqrt(phi))\n",
    "  model <- list(\n",
    "    data = list(\n",
    "      X = X,\n",
    "      y = y,\n",
    "      u = u,\n",
    "      n_j = n_j\n",
    "    ),\n",
    "    z = z,\n",
    "    M = M,\n",
    "    N = N,\n",
    "    params = list(\n",
    "      beta = beta,\n",
    "      phi = phi,\n",
    "      psi = psi,\n",
    "      a = a,\n",
    "      b = b\n",
    "    )\n",
    "  )\n",
    "  return(model)\n",
    "}\n",
    "\n",
    "syn_data <- syn_multi_level_reg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the EM algorithm the uncover the latent factors and fit the multilevel regression model. To do so we first need to derive the *expected* complete data log-likelihood (CLL):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&& Q(\\theta, \\theta_{t-1}) &= \\mathbb{E}_{p(\\mathbf{z}|\\mathbf{y}, \\mathbf{X}, \\theta_{t-1})} \\left[ \\log \\ell (\\theta | \\mathbf{y}, \\mathbf{X}, \\mathbf{z}) \\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Below we provide a high-level overview of the involved mathematics. Derivations can be found in the appendix if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-step\n",
    "\n",
    "Generally it can be difficult to compute the expected CLL, but here it is fairly straight-forward to compute the intergral over $\\mathbf{z}$ since the posterior density $p(\\mathbf{z}|\\mathbf{y}, \\mathbf{X}, \\theta_{t-1})$ is mathematically tractable due to conjugacy. Specifically we have for the posterior density\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&& z_j|\\mathbf{y}_j,\\mathbf{X}_j, \\theta&\\sim \\mathcal{N}(\\mu_j, v_j) \\\\\n",
    "&& v_j &= \\frac{1}{\\frac{n_j}{\\phi}+\\frac{1}{\\psi}} \\\\\n",
    "&& \\mu_j &= \\frac{\\frac{n_j}{\\phi} (\\bar{\\mathbf{y}}_j - \\bar{\\mathbf{X}}_j \\beta)}{\\frac{n_j}{\\phi}+\\frac{1}{\\psi}} + \\frac{\\frac{1}{\\psi} (\\mathbf{u}^T_j \\gamma)}{\\frac{n_j}{\\phi}+\\frac{1}{\\psi}} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and hence for the expected CLL\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&& Q(\\theta, \\theta_{t-1})&= - {1\\over{2}} \\left( \n",
    "N \\log 2\\pi\\phi + \n",
    "{1\\over{\\phi}} \n",
    "\\left( \n",
    "(\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta) - 2(\\mathbf{y} - \\mathbf{X} \\beta)^T \\mu_N + \\mathbf{1}^T_N (\\mu_N^2+\\mathbf{v}_N) \n",
    "\\right) \n",
    "\\\\ + M \\log 2\\pi\\psi +\n",
    "\\left( \n",
    "(\\mathbf{u} \\gamma)^T (\\mathbf{u} \\gamma) - 2(\\mathbf{u} \\gamma)^T\\mu_M + \\mathbf{1}^T_M (\\mu_M^2+\\mathbf{v}_M) \n",
    "\\right) \n",
    "\\right)\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\mu_M,\\mathbf{v}_M$ are $(M\\times 1)$ vectors of posterior means and variances, respectively, and $\\mu_M,\\mathbf{v}_M$ are their corresponding stacked versions with elements $\\mu_j, v_j$ repeated $n_j$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M-step\n",
    "\n",
    "Since $Q(\\theta, \\theta_{t-1})$ is just a quadratic form, we can maximise the expected CLL through analytical solutions to the first-order condition $\\nabla_{\\theta}Q(\\theta, \\theta_{t-1}) = \\mathbf{0}$. It is straight-forward to show that\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&& \\beta^{\\text{MLE}}&= (\\mathbf{X}^T\\mathbf{X})^{-1} (\\mathbf{X}^T \\mathbf{y} - \\mathbf{X}^T \\mu_N) \\\\\n",
    "&& \\phi^{\\text{MLE}}&= {1\\over{N}} \\left( (\\mathbf{y} - \\mathbf{X} \\beta^{\\text{MLE}})^T (\\mathbf{y} - \\mathbf{X} \\beta^{\\text{MLE}}) - 2(\\mathbf{y} - \\mathbf{X} \\beta^{\\text{MLE}})^T \\mu_N + \\mathbf{1}^T_N (\\mu_N^2+\\mathbf{v}_N) \\right) \\\\\n",
    "&& \\gamma^{\\text{MLE}}&= (\\mathbf{u}^T\\mathbf{u})^{-1} \\mathbf{u}^T \\mu_M\\\\\n",
    "&& \\psi^{\\text{MLE}}&= {1\\over{M}} \\left( (\\mathbf{u} \\gamma^{\\text{MLE}})^T (\\mathbf{u} \\gamma^{\\text{MLE}}) - 2(\\mathbf{u} \\gamma^{\\text{MLE}})^T\\mu_M + \\mathbf{1}^T_M (\\mu_M^2+\\mathbf{v}_M)  \\right) \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "We shall now go through how the estimation of the multilevel regression model through EM can be programmed in R. As a first step we use a simple helper function that sets up the model: `multilevel_model` takes as inputs the $(N \\times K)$ matrix of inidividual-level predictors `X`, the $(N \\times 1)$ output vector `y`, the $(M \\times L)$ matrix of group-level predictors `u` and an $(M \\times 1)$ vector `n_j` that indicates group sizes. It returns a an object of class `multilevel_model`. (Using a class is not strictly necessary but will turn out to be convenient later as we shall see.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilevel_model <- function(\n",
    "  X,\n",
    "  y,\n",
    "  u,\n",
    "  n_j\n",
    ") {\n",
    "  # Group index:\n",
    "  group <- rep.int(1:nrow(u), times=n_j)\n",
    "  u <- matrix(rep.int(u, times=n_j))\n",
    "  U <- cbind(1, unique(u))\n",
    "  model <- list(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    u=u,\n",
    "    U=U,\n",
    "    group=group,\n",
    "    n_j=n_j\n",
    "  )\n",
    "  class(model) <- \"multilevel_model\"\n",
    "  return(model)\n",
    "}\n",
    "# Prepare model:\n",
    "model <- multilevel_model(syn_data$data$X, syn_data$data$y, syn_data$data$u, syn_data$data$n_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model set up we can introduce the main `em` method that fits the model. If no initial guesses for the parameter vector $\\theta$ are supplied, the algorithm will take random intial guesses excpet for $\\beta_0$ which is set to the pooled OLS estimate. The algorithm then iteratively performs the E-step and M-step until convergence. The method finally returns an object of class `em_output` (again not strictly necessary but convenient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --------------------- EM algorithm: --------------------- ##\n",
    "em.multilevel_model <- function(\n",
    "  model,\n",
    "  theta0=NULL,\n",
    "  tol=1e-9,\n",
    "  print_progress=T\n",
    ") {\n",
    "  # Initialization: ----\n",
    "  if (is.null(theta0)) {\n",
    "    theta0 <- list(\n",
    "      beta = qr.solve(model$X, model$y), # initialize as pooled OLS\n",
    "      phi = runif(1, 0, 100),\n",
    "      gamma = matrix(rnorm(2)),\n",
    "      psi = runif(1, 0, 100)\n",
    "    )\n",
    "  }\n",
    "  converged <- FALSE # initialize convergence condition as false\n",
    "  iter_count <- 1\n",
    "  # Recursion: ----\n",
    "  while (!converged) {\n",
    "    if (print_progress) {\n",
    "      print(iter_count)\n",
    "    }\n",
    "    # 1.) E-step: ----\n",
    "    posterior_moments <- posterior(model, theta0) # returns and (M x 1) vectors of posteriors\n",
    "    Q0 <- Q(model, theta0, posterior_moments) # to compare below\n",
    "    # 2.) M-step: ----\n",
    "    theta <- update_theta(model, theta0, posterior_moments)\n",
    "    # Recalculate given MAP parameter estimates:\n",
    "    Q1 <- Q(model, theta, posterior_moments)\n",
    "    # Check for convergence:\n",
    "    if (print_progress) {\n",
    "      print(sprintf(\"Improvement of %0.2f\",Q1-Q0))\n",
    "    }\n",
    "    converged <- Q1-Q0 < tol\n",
    "    theta0 <- theta # new theta 0\n",
    "    iter_count <- iter_count + 1\n",
    "  }\n",
    "  # Allocate and return output:\n",
    "  output <- list(\n",
    "    model = model,\n",
    "    coefficients = theta,\n",
    "    n_iter = iter_count - 1\n",
    "  )\n",
    "  class(output) <- \"em_output\"\n",
    "  return(output)\n",
    "}\n",
    "\n",
    "em <- function(\n",
    "  model,\n",
    "  theta0=NULL,\n",
    "  tol=1e-9,\n",
    "  print_progress=T\n",
    ") {\n",
    "  UseMethod(\"em\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will note that this function depends on a few helper functions: `posterior` - returns the first two moments of the posterior density of the latent variable -, `update_theta` - updates parameters according to the first-order conditions - and finally `Q` which compute the expected CLL for a given $\\theta$ and posterior moments. \n",
    "These functions are methods that relate to the `multilevel_model` class we introdcued above, since they depend on the distribution we assume for the data and latent variables. Setting the code up this way is convenient since according to our assumption we can alter these methods and use the `em` method independently in the same way as before. Before running the `em` method we need to source the methods we just introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `posterior`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.multilevel_model <- function(\n",
    "  model,\n",
    "  theta\n",
    ") {\n",
    "  n_j <- model$n_j\n",
    "  list2env(theta, envir = environment())\n",
    "  # Posterior density ----\n",
    "  var_posterior <- function(phi, psi, n_j) {\n",
    "    v <- (n_j*phi^(-1) + psi^(-1))^(-1)\n",
    "    return(v)\n",
    "  }\n",
    "  # Posterior mean ----\n",
    "  mean_posterior <- function(phi, psi, n_j, v, mu_a, mu_b) {\n",
    "    v * n_j * phi^(-1) * (mu_a) +\n",
    "      v * psi^(-1) * (mu_b)\n",
    "  }\n",
    "  # Compute density ----\n",
    "  p <- t(\n",
    "    sapply(\n",
    "      1:length(n_j),\n",
    "      function(j) {\n",
    "        y <- matrix(model$y[model$group==j])\n",
    "        X <- matrix(model$X[model$group==j,], ncol = ncol(model$X))\n",
    "        U <- matrix(model$U[j,], ncol = ncol(model$U))\n",
    "        if (nrow(X) > 1) {\n",
    "          mu_a <- mean(y) - colMeans(X) %*% beta\n",
    "        } else {\n",
    "          mu_a <- mean(y) - X %*% beta\n",
    "        }\n",
    "        mu_b <- unique(U) %*% gamma\n",
    "        # Variance:\n",
    "        v <- var_posterior(phi, psi, n_j[j])\n",
    "        # Mean:\n",
    "        mu <- mean_posterior(phi, psi, n_j[j], v, mu_a, mu_b)\n",
    "        # Density:\n",
    "        return(c(v=v, mu=mu))\n",
    "      }\n",
    "    )\n",
    "  )\n",
    "  return(p)\n",
    "}\n",
    "\n",
    "posterior <- function(model, theta) {\n",
    "  UseMethod(\"posterior\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `update_theta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_theta.multilevel_model <- function(model, theta, p) {\n",
    "  # Gather:\n",
    "  n_j <- model$n_j\n",
    "  list2env(theta, envir = environment())\n",
    "  X <- model$X\n",
    "  y <- model$y\n",
    "  N <- nrow(y)\n",
    "  M <- length(n_j)\n",
    "  U <- model$U\n",
    "  # Posterior moments:\n",
    "  mu_M <- matrix(p[,\"mu\"])\n",
    "  v_M <- matrix(p[,\"v\"])\n",
    "  mu_N <- matrix(rep.int(mu_M, times=n_j))\n",
    "  v_N <- matrix(rep.int(v_M, times=n_j))\n",
    "  # beta: ----\n",
    "  beta_map <- qr.solve(crossprod(X), (crossprod(X,y) - crossprod(X, mu_N)))\n",
    "  theta$beta <- beta_map # update\n",
    "  # phi: ----\n",
    "  phi_map <- (1/N) *\n",
    "    (crossprod(y-X%*%beta_map) - 2 * crossprod(y - X %*% beta_map, mu_N) + sum( mu_N^2 + v_N ))\n",
    "  theta$phi <- phi_map # update phi\n",
    "  # gamma: ----\n",
    "  gamma_map <- qr.solve(crossprod(U), crossprod(U,mu_M))\n",
    "  theta$gamma <- gamma_map # update gamma\n",
    "  # psi: ----\n",
    "  psi_map <- (1/M) *\n",
    "    (crossprod(U %*% gamma_map) + sum( mu_M^2 + v_M ) - 2 * crossprod(U %*% gamma_map, mu_M))\n",
    "  theta$psi <- psi_map # update psi\n",
    "  return(theta)\n",
    "}\n",
    "\n",
    "update_theta <- function(model, theta, p) {\n",
    "  UseMethod(\"update_theta\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Q`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.multilevel_model <- function(model, theta, p) {\n",
    "  n_j <- model$n_j\n",
    "  list2env(theta, envir = environment())\n",
    "  y <- model$y\n",
    "  X <- model$X\n",
    "  U <- model$U\n",
    "  N <- nrow(y)\n",
    "  M <- length(n_j)\n",
    "  # Posterior moments:\n",
    "  mu_M <- matrix(p[,\"mu\"])\n",
    "  v_M <- matrix(p[,\"v\"])\n",
    "  mu_N <- matrix(rep.int(mu_M, times=n_j))\n",
    "  v_N <- matrix(rep.int(v_M, times=n_j))\n",
    "  # Compute:\n",
    "  A <- N * log(2*pi*phi)\n",
    "  B <- phi^(-1) * ( crossprod(y - X %*% beta) - 2 * crossprod(y - X %*% beta, mu_N) + sum( mu_N^2 + v_N ) )\n",
    "  C <- M * log(2*pi*psi)\n",
    "  D <- psi^(-1) * ( crossprod(U %*% gamma) + sum( mu_M^2 + v_M ) - 2 * crossprod(U %*% gamma, mu_M))\n",
    "  value <- (-1/2) * ( A + B + C + D )\n",
    "  return(value)\n",
    "}\n",
    "\n",
    "Q <- function(model, theta, p) {\n",
    "  UseMethod(\"Q\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact there is one further method relating to the `multilevel_model` which is used under the hood to infer the latent variables given our final estimate of $\\theta$. The `infer_latent` method is not used anywhere inside the `em` method since the algorithm that fits the model need not know the estimated values of the latent factors at any point - it depends solely on estimates of their posterior moments. But estimated latent variables will be important in order to predict from the fitted model among other things, so we introduce the method that infers them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_latent.multilevel_model <- function(model, theta) {\n",
    "  n_j <- model$n_j\n",
    "  list2env(theta, envir = environment())\n",
    "  z <- model$U %*% gamma\n",
    "  return(z)\n",
    "}\n",
    "\n",
    "infer_latent <- function(model, theta) {\n",
    "  UseMethod(\"infer_latent\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us briefly introduce a couple of standard methods relating the model output - i.e. the `em_output` object returned by the `em` method. We will leave these uncommented as they perform standard procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --------------------- Standard methods: --------------------- ##\n",
    "predict.em_output <- function(em_output) {\n",
    "  # Predictors: ----\n",
    "  X <- em_output$model$X\n",
    "  beta <- em_output$coefficients$beta\n",
    "  # Latent variable estimates: ----\n",
    "  Z_M <- infer_latent(em_output$model, em_output$coefficients)\n",
    "  n_j <- em_output$model$n_j\n",
    "  Z_N <- rep.int(Z_M, n_j)\n",
    "  # Fit: ----\n",
    "  fitted <- Z_N + X %*% beta\n",
    "  return(fitted)\n",
    "}\n",
    "\n",
    "predict <- function(em_output) {\n",
    "  UseMethod(\"predict\")\n",
    "}\n",
    "\n",
    "residuals.em_output <- function(em_output) {\n",
    "  y <- em_output$model$y\n",
    "  fitted <- predict(em_output)\n",
    "  res <- y - fitted\n",
    "  return(res)\n",
    "}\n",
    "\n",
    "residuals <- function(em_output) {\n",
    "  UseMethod(\"residuals\")\n",
    "}\n",
    "\n",
    "coefficients.em_output <- function(em_output) {\n",
    "  beta <- em_output$coefficients$beta\n",
    "  if (!is.null(colnames(em_output$model$X))) {\n",
    "    beta_names <- colnames(em_output$model$X)\n",
    "  } else {\n",
    "    beta_names <- sprintf(\"X_%i\", 1:length(beta))\n",
    "  }\n",
    "  Z_M <- infer_latent(em_output$model, em_output$coefficients)\n",
    "  Z_M_names <- sprintf(\"z_%i\", 1:nrow(Z_M))\n",
    "  coeffs <- data.table::data.table(\n",
    "    Covariate = c(beta_names, Z_M_names),\n",
    "    Coefficient = c(beta, Z_M)\n",
    "  )\n",
    "  return(coeffs)\n",
    "}\n",
    "\n",
    "coefficients <- function(em_output) {\n",
    "  UseMethod(\"coefficients\")\n",
    "}\n",
    "\n",
    "rsquared.em_output <- function(em_output) {\n",
    "  y <- em_output$model$y\n",
    "  fitted <- predict(em_output)\n",
    "  rss <- sum((fitted - y)^2)\n",
    "  tss <- sum((y-mean(y))^2)\n",
    "  rsq <- 1 - rss/tss\n",
    "  return(rsq)\n",
    "}\n",
    "\n",
    "rsquared <- function(em_output) {\n",
    "  UseMethod(\"rsquared\")\n",
    "}\n",
    "\n",
    "print.em_output <- function(em_output) {\n",
    "  cat(\"Coefficient estimates: -----\\n\")\n",
    "  print(coefficients(em_output))\n",
    "  cat(\"Precision estimates: -----\\n\")\n",
    "  cat(sprintf(\"Data: %0.2f\\n\",(em_output$coefficients$phi)^(-1)))\n",
    "  cat(sprintf(\"Latent: %0.2f\\n\",(em_output$coefficients$psi)^(-1)))\n",
    "  cat(sprintf(\"R-squared: %0.2f\\n\", rsquared(em_output)))\n",
    "  cat(\"Performance: -----\\n\")\n",
    "  cat(sprintf(\"Number of iterations: %0.2f\\n\", em_output$n_iter))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First run\n",
    "\n",
    "Finally, let us a perform a first run of our model. With the synthetic data and the corresponding `multilevel_model` already prepared we can simply run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coefficient estimates: -----\n",
       "      Covariate Coefficient\n",
       "   1:       X_1  1.00604683\n",
       "   2:       X_2  0.09589592\n",
       "   3:       z_1  0.71802461\n",
       "   4:       z_2  0.88875274\n",
       "   5:       z_3  1.81341163\n",
       "  ---                      \n",
       " 998:     z_996  0.96122204\n",
       " 999:     z_997  1.56106945\n",
       "1000:     z_998  0.30935784\n",
       "1001:     z_999  0.73759356\n",
       "1002:    z_1000  0.87892499\n",
       "Precision estimates: -----\n",
       "Data: 9.96\n",
       "Latent: 19.76\n",
       "R-squared: 0.90\n",
       "Performance: -----\n",
       "Number of iterations: 16.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "em(model, print_progress = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the output, the algorithm converged after 16 iterations. It attributes a precision to the group-level information roughly twice as high as the individual-level data, which was expected given the default parameter choices from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
